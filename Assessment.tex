\section{Assessment}
%Typically, authors will present in this section the critical experiments or studies that were conducted in the process of methods testing, the results of those studies, and the proof of concept they provide. The Assessment section may also be used to present the results of re-evaluations of existing methods, intercomparison and intercalibration experiments, and metaanalyses. It should include not only the factual results, but their interpretation and the conclusions reached from them. The assessment should provide the answers to such basic questions as:
%How do you know that your method really works?
%How well does your method work?
%What are the method's strengths and limitations?
%How difficult or expensive is your method to adopt and use?
%Does an existing method indeed have a fundamental flaw that needs to be addressed?
%How well did alternative methods agree?
%The methods assessment must address statistical properties of new methods, such as precision, accuracy, and detection limits. These elements are particularly important if a new method is intended to supplant an established procedure.
%If a method involves any subjective decision by an operator, or is dependent on operator skill, the manuscript must address explicitly the extent to which operator performance affects the statistical properties of the method. As an example: epifluorescence microscopy is often used to enumerate aquatic bacteria, but usually requires subjective decisions on the part of the individual doing the counting. The extent to which such subjective decisions influence results would need to be measured.
%Authors should assess the ease or difficulty of setting up and employing the method.
%One effective and persuasive technique to demonstrate the utility of a new method is to apply it successfully to a real-world problem. Authors are not required to demonstrate proof-of-concept through a real-world application, in order to submit a methods manuscript to Limnology and Oceanography: Methods. Demonstrations of the effectiveness of a method under controlled experimental conditions are equally acceptable, provided that the authors can argue successfully that the transition to real-world applications should not present potentially insurmountable obstacles.

%Talk about speed, quality, repeatability
% figures of typical results
We characterize the techniques performance based on three expeditions to Lizard Island, in which over 20 (what's the actual number?) spiral surveys were revisited on each trip.
% repeat survey
\subsection{Operational simplicity and survey speed}
The equipment used is easy to handle. Driving a star picket (in reef) is a standard task for field ecologists. Once clipped onto the line, the swimmer only needs to advance while keeping tension on the line and maintain a desired altitude over the bottom (the altimeter display on the imaging platform is useful guide).
Using a calibrated stereo camera provides scale information that otherwise requires additional infrastructure and effort (such as deploying markers acting as ground control points and measuring the distance between them). 
The time to perform a reef record is consistent, with slight variations depending on currents and waves. During the May 2015 field season, we performed 35 reef records around Lizard Island. The average duration was 15:26 (std dev 01:43), with a maximum of 18:47 and a minimum of 12:58. In terms of stereo pairs, that corresponds to an average of 1853 pairs (std dev 205.3), a maximum of 2255, and a minimum of 1557 images. The number of instances of overlap between images pairs found was on average 19286.3 (std dev 7098.1), with a maximum of 33168 and a minimum of 6194. This depends on on swimming speed along track, as well as altitude across track since it determines the image footprint, and thus the overlap between revolutions on the spiral path.
%over 35 surveys with a loop array of length 35 [sanity check]
%mean poses 1853.2, mean sec 926.6, mean 15:26 
%mean loops 19286.3428571
%std dev poses 205.308381292
%std dev loops 7098.12946765
%min and max poses
%poses max 2255 , min 1557
%max poses 2255, max sec 1127.5, max 18:47 
%min poses 1557, min sec 778.5, min 12:58 
%min and max loops
%loops max 33168 , min 6194


\subsection{Georeferencing}
For shallow, clear water surveys (~4m or less), while the platform is near the surface it is possible to simultaneously acquire imagery of the bottom and GPS fixes. As long as one image has a GPS fix associated with it and the image overlaps with other images part of the images at survey altitude, the whole reconstruction will be georeferenced. Alternatively, any point of the survey (typically where the star picket is driven into the bottom) can be surveyed in and that location entered manually into the reconstruction. Using a SLAM filter allows fusing multiple GPS fixes as the platform follows the spiral path, which improves the quality of the georeferencing by reducing the effects of noise and outliers present when operating near the air-water interface with waves.
The fusion of depth and attitude ensures that the reconstruction is oriented properly and at the correct depth.

\subsection{Visual survey quality}
The spiral survey by design allows for constant separation between passes, when matched to the field of view and altitude it guarantees high overlap across successive passes. For our setup this resulted in a network of cameras with X-Y images and Z links on average. Each camera was connected to U other cameras on average and V cameras that are temporally distant (Figures? Histograms?)

\subsection{Repeatability}
Given a printout of the mosaic from a previous survey and the GPS coordinate, an experienced diver can relocate the central point in seconds to a few minutes, depending on how much the site has changed.
Figure T presents examples of revisited sites on Lizard Island for April 2014, October 2014 and May 2015.


    
  
  